apiVersion: batch.volcano.sh/v1alpha1
kind: Job
metadata:
  generateName: gcr-mpi-scalability-hari-
  namespace: gcr-admin-test1
spec:
  queue: default
  minAvailable: 479
  plugins:
    ssh: []
    svc: []
    env: []
    mpi : ["--master=server", "--worker=client"]
  tasks:
    - name: server
      replicas: 1
      template:
        metadata:
          labels:
            app: allpair-mpi
            role: server
        spec:
          schedulerName: volcano
          restartPolicy: Never
          volumes:
            - name: dshm
              emptyDir:
                medium: Memory
                sizeLimit: 256Gi
            - name: data
              persistentVolumeClaim:
                claimName: pvc-vast-gcr-admin-test1
            - name: sys
              hostPath:
                path: /sys
                type: Directory
          tolerations:
            - key: "rdma"
              operator: "Exists"
              effect: "NoSchedule"
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          affinity:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchLabels:
                      app: allpair-mpi
                  topologyKey: kubernetes.io/hostname
          containers:
            - name: server
              image: nvcr.io/nvidia/pytorch:25.10-py3
              env:
                - name: gcrnode
                  valueFrom:
                    fieldRef:
                      fieldPath: spec.nodeName
                - name: ALLPAIR_DEBUG
                  value: "1"
              volumeMounts:
                - name: dshm
                  mountPath: /dev/shm
                - name: data
                  mountPath: /data
                - name: sys
                  mountPath: /sys
                  readOnly: true
              ports:
                - name: rdma
                  containerPort: 18515
              command: ["/bin/bash", "-lc"]
              args:
                - |
                  set -xeo pipefail
                  
                  # 1. Clone Repo
                  git clone https://github.com/IamNirmata/Cluster-Validation-Runbook.git /opt/Cluster-Validation-Runbook                 
                  # 2. Source the common setup script
                  # This installs/starts sshd AND exports MASTER_ADDR/PORT
                  source /opt/Cluster-Validation-Runbook/scalability/env.sh
                  
                  # 3. Wait for workers to be ready for SSH
                  bash /opt/Cluster-Validation-Runbook/scalability/wait-for-ssh.sh
                  
                  # 4. Run the main test suite
                  echo "Starting Test Suite..."
                  cd /opt/Cluster-Validation-Runbook/scalability
                  
                  echo "Making scripts executable..."
                  chmod +x *.sh

                  bash ./latency.sh
                  bash ./bw.sh
                  bash ./scale.sh
                  
                  echo "Tests finished. Sleeping."
                  sleep infinity
              resources:
                requests:
                  nvidia.com/gpu: "8"
                  cpu: "100"
                  memory: "1500Gi"
                  rdma/rdma_shared_device_a: "1"
                limits:
                  nvidia.com/gpu: "8"
                  cpu: "100"
                  memory: "1500Gi"
                  rdma/rdma_shared_device_a: "1"
    - name: client
      replicas: 478
      template:
        metadata:
          labels:
            app: allpair-mpi
            role: client
        spec:
          schedulerName: volcano
          restartPolicy: Never
          volumes:
            - name: dshm
              emptyDir:
                medium: Memory
                sizeLimit: 256Gi
            - name: data
              persistentVolumeClaim:
                claimName: pvc-vast-gcr-admin-test1
            - name: sys
              hostPath:
                path: /sys
                type: Directory
          tolerations:
            - key: "rdma"
              operator: "Exists"
              effect: "NoSchedule"
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          affinity:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchLabels:
                      app: allpair-mpi
                  topologyKey: kubernetes.io/hostname
          containers:
            - name: client
              image: nvcr.io/nvidia/pytorch:25.10-py3
              env:
                - name: gcrnode
                  valueFrom:
                    fieldRef:
                      fieldPath: spec.nodeName
                - name: ALLPAIR_DEBUG
                  value: "1"
              volumeMounts:
                - name: dshm
                  mountPath: /dev/shm
                - name: data
                  mountPath: /data
                - name: sys
                  mountPath: /sys
                  readOnly: true
              ports:
                - name: rdma
                  containerPort: 18515
              command: ["/bin/bash", "-lc"]
              args:
                - |
                  set -xeo pipefail
                  # 1. Clone Repo
                    git clone https://github.com/IamNirmata/Cluster-Validation-Runbook.git /opt/Cluster-Validation-Runbook                 
                  # 2. Source the common setup script
                  # This installs/starts sshd
                  source /opt/Cluster-Validation-Runbook/scalability/env.sh
                  
                  echo "Worker ready. Sleeping."
                  sleep infinity
              resources:
                requests:
                  nvidia.com/gpu: "8"
                  cpu: "100"
                  memory: "1500Gi"
                  rdma/rdma_shared_device_a: "1"
                limits:
                  nvidia.com/gpu: "8"
                  cpu: "100"
                  memory: "1500Gi"
                  rdma/rdma_shared_device_a: "1"
